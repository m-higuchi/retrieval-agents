{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from retrieval_agents import adaptive_rag_graph, configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(configurable={\"user_id\": \"test_user\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = adaptive_rag_graph.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:retrieval_graph.adaptive_rag_graph:LLM: openai/gpt-4o\n",
      "DEBUG:retrieval_graph.adaptive_rag_graph:structured_llm created\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'FieldInfo' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m graph.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m}, config=config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2741\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2739\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2740\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2741\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2742\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2743\u001b[39m     config,\n\u001b[32m   2744\u001b[39m     stream_mode=stream_mode,\n\u001b[32m   2745\u001b[39m     output_keys=output_keys,\n\u001b[32m   2746\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2747\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2748\u001b[39m     debug=debug,\n\u001b[32m   2749\u001b[39m     **kwargs,\n\u001b[32m   2750\u001b[39m ):\n\u001b[32m   2751\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2752\u001b[39m         latest = chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2626\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2620\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2621\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   2622\u001b[39m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2623\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2624\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   2625\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2626\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2627\u001b[39m         loop.tasks.values(),\n\u001b[32m   2628\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2629\u001b[39m         retry_policy=\u001b[38;5;28mself\u001b[39m.retry_policy,\n\u001b[32m   2630\u001b[39m         get_waiter=get_waiter,\n\u001b[32m   2631\u001b[39m     ):\n\u001b[32m   2632\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2633\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   2634\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langgraph/graph/branch.py:192\u001b[39m, in \u001b[36mBranch._aroute\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    191\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.path.ainvoke(value, config)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langgraph/utils/runnable.py:419\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m coro = cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs))\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(coro, context=context)\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    421\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/retrieval_graph/adaptive_rag_graph.py:286\u001b[39m, in \u001b[36mroute_question\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m#source = await question_router.ainvoke({\"question\": question})\u001b[39;00m\n\u001b[32m    285\u001b[39m source = \u001b[38;5;28;01mawait\u001b[39;00m question_router.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages})\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source.datasource == \u001b[33m\"\u001b[39m\u001b[33mweb_search\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweb_search\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m source.datasource == \u001b[33m\"\u001b[39m\u001b[33mvectorstore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/runnables/base.py:3089\u001b[39m, in \u001b[36mRunnableSequence.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3087\u001b[39m     part = functools.partial(step.ainvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[32m   3088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m asyncio_accepts_context():\n\u001b[32m-> \u001b[39m\u001b[32m3089\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(part(), context=context)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   3090\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3091\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(part())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/runnables/base.py:5453\u001b[39m, in \u001b[36mRunnableBindingBase.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5446\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5447\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m   5448\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5451\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5452\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.ainvoke(\n\u001b[32m   5454\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5455\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5456\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5457\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:353\u001b[39m, in \u001b[36mBaseChatModel.ainvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    345\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m     **kwargs: Any,\n\u001b[32m    351\u001b[39m ) -> BaseMessage:\n\u001b[32m    352\u001b[39m     config = ensure_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     llm_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate_prompt(\n\u001b[32m    354\u001b[39m         [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    355\u001b[39m         stop=stop,\n\u001b[32m    356\u001b[39m         callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    357\u001b[39m         tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    358\u001b[39m         metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    359\u001b[39m         run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    360\u001b[39m         run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    361\u001b[39m         **kwargs,\n\u001b[32m    362\u001b[39m     )\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m, llm_result.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:905\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    896\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m    898\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    902\u001b[39m     **kwargs: Any,\n\u001b[32m    903\u001b[39m ) -> LLMResult:\n\u001b[32m    904\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m    906\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m    907\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:794\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Asynchronously pass a sequence of prompts to a model and return generations.\u001b[39;00m\n\u001b[32m    764\u001b[39m \n\u001b[32m    765\u001b[39m \u001b[33;03mThis method should make use of batched calls for models that expose a batched\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    789\u001b[39m \u001b[33;03m        prompt and additional model provider-specific output.\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    791\u001b[39m ls_structured_output_format = kwargs.pop(\n\u001b[32m    792\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mls_structured_output_format\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    793\u001b[39m ) \u001b[38;5;129;01mor\u001b[39;00m kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mstructured_output_format\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m ls_structured_output_format_dict = \u001b[43m_format_ls_structured_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mls_structured_output_format\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m params = \u001b[38;5;28mself\u001b[39m._get_invocation_params(stop=stop, **kwargs)\n\u001b[32m    799\u001b[39m options = {\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop, **ls_structured_output_format_dict}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:152\u001b[39m, in \u001b[36m_format_ls_structured_output\u001b[39m\u001b[34m(ls_structured_output_format)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ls_structured_output_format:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    149\u001b[39m         ls_structured_output_format_dict = {\n\u001b[32m    150\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mls_structured_output_format\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    151\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m: ls_structured_output_format.get(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m, {}),\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mschema\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mconvert_to_json_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mls_structured_output_format\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    155\u001b[39m             }\n\u001b[32m    156\u001b[39m         }\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    158\u001b[39m         ls_structured_output_format_dict = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/utils/function_calling.py:574\u001b[39m, in \u001b[36mconvert_to_json_schema\u001b[39m\u001b[34m(schema, strict)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_json_schema\u001b[39m(\n\u001b[32m    569\u001b[39m     schema: Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mtype\u001b[39m[BaseModel], Callable, BaseTool],\n\u001b[32m    570\u001b[39m     *,\n\u001b[32m    571\u001b[39m     strict: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    572\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    573\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert a schema representation to a JSON schema.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     openai_tool = \u001b[43mconvert_to_openai_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    576\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(openai_tool, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    577\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m openai_tool\n\u001b[32m    578\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m openai_tool[\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    579\u001b[39m     ):\n\u001b[32m    580\u001b[39m         error_message = \u001b[33m\"\u001b[39m\u001b[33mInput must be a valid OpenAI-format tool.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/utils/function_calling.py:564\u001b[39m, in \u001b[36mconvert_to_openai_tool\u001b[39m\u001b[34m(tool, strict)\u001b[39m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (tool.get(\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).startswith(\u001b[33m\"\u001b[39m\u001b[33mweb_search_preview\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    563\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tool\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m oai_function = \u001b[43mconvert_to_openai_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m: oai_function}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/utils/function_calling.py:470\u001b[39m, in \u001b[36mconvert_to_openai_function\u001b[39m\u001b[34m(function, strict)\u001b[39m\n\u001b[32m    468\u001b[39m         oai_function[\u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m] = function_copy\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_basemodel_subclass(function):\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     oai_function = cast(\u001b[33m\"\u001b[39m\u001b[33mdict\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43m_convert_pydantic_to_openai_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_typeddict(function):\n\u001b[32m    472\u001b[39m     oai_function = cast(\n\u001b[32m    473\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdict\u001b[39m\u001b[33m\"\u001b[39m, _convert_typed_dict_to_openai_function(cast(\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m, function))\n\u001b[32m    474\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/langchain_core/utils/function_calling.py:155\u001b[39m, in \u001b[36m_convert_pydantic_to_openai_function\u001b[39m\u001b[34m(model, name, description, rm_titles)\u001b[39m\n\u001b[32m    153\u001b[39m     schema = model.model_json_schema()  \u001b[38;5;66;03m# Pydantic 2\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mschema\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     schema = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pydantic 1\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    157\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mModel must be a Pydantic model.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/main.py:664\u001b[39m, in \u001b[36mBaseModel.schema\u001b[39m\u001b[34m(cls, by_alias, ref_template)\u001b[39m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cached\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m s = \u001b[43mmodel_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28mcls\u001b[39m.__schema_cache__[(by_alias, ref_template)] = s\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/schema.py:188\u001b[39m, in \u001b[36mmodel_schema\u001b[39m\u001b[34m(model, by_alias, ref_prefix, ref_template)\u001b[39m\n\u001b[32m    186\u001b[39m model_name_map = get_model_name_map(flat_models)\n\u001b[32m    187\u001b[39m model_name = model_name_map[model]\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m m_schema, m_definitions, nested_models = \u001b[43mmodel_process_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_template\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m nested_models:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# model_name is in Nested models, it has circular references\u001b[39;00m\n\u001b[32m    193\u001b[39m     m_definitions[model_name] = m_schema\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/schema.py:581\u001b[39m, in \u001b[36mmodel_process_schema\u001b[39m\u001b[34m(model, by_alias, model_name_map, ref_prefix, ref_template, known_models, field)\u001b[39m\n\u001b[32m    579\u001b[39m     s[\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m] = doc\n\u001b[32m    580\u001b[39m known_models.add(model)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m m_schema, m_definitions, nested_models = \u001b[43mmodel_type_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mknown_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknown_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m s.update(m_schema)\n\u001b[32m    590\u001b[39m schema_extra = model.__config__.schema_extra\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/schema.py:622\u001b[39m, in \u001b[36mmodel_type_schema\u001b[39m\u001b[34m(model, by_alias, model_name_map, ref_template, ref_prefix, known_models)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, f \u001b[38;5;129;01min\u001b[39;00m model.__fields__.items():\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m         f_schema, f_definitions, f_nested_models = \u001b[43mfield_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m            \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m            \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m            \u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m            \u001b[49m\u001b[43mknown_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknown_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipField \u001b[38;5;28;01mas\u001b[39;00m skip:\n\u001b[32m    631\u001b[39m         warnings.warn(skip.message, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/schema.py:248\u001b[39m, in \u001b[36mfield_schema\u001b[39m\u001b[34m(field, by_alias, model_name_map, ref_prefix, ref_template, known_models)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfield_schema\u001b[39m(\n\u001b[32m    223\u001b[39m     field: ModelField,\n\u001b[32m    224\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     known_models: Optional[TypeModelSet] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    230\u001b[39m ) -> Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Dict[\u001b[38;5;28mstr\u001b[39m, Any], Set[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Process a Pydantic field and return a tuple with a JSON Schema for it as the first item.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    Also return a dictionary of definitions with models as keys and their schemas as values. If the passed field\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m \u001b[33;03m    :return: tuple of the schema for this field and additional definitions\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     s, schema_overrides = \u001b[43mget_field_info_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     validation_schema = get_field_schema_validations(field)\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validation_schema:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/schema.py:216\u001b[39m, in \u001b[36mget_field_info_schema\u001b[39m\u001b[34m(field, schema_overrides)\u001b[39m\n\u001b[32m    213\u001b[39m     schema_overrides = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field.required \u001b[38;5;129;01mand\u001b[39;00m field.default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_callable_type(field.outer_type_):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     schema_[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mencode_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     schema_overrides = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m schema_, schema_overrides\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/schema.py:995\u001b[39m, in \u001b[36mencode_default\u001b[39m\u001b[34m(dft)\u001b[39m\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpydantic_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdft\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/pydantic/v1/json.py:90\u001b[39m, in \u001b[36mpydantic_encoder\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m encoder(obj)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# We have exited the for loop without finding a suitable encoder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not JSON serializable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type 'FieldInfo' is not JSON serializable",
      "During task with name '__start__' and id '8945c8b0-cc84-7188-c651-c8d53274aafe'"
     ]
    }
   ],
   "source": [
    "result = await graph.ainvoke({\"question\": \"test\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:retrieval_graph.adaptive_rag_graph:LLM: openai/gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:retrieval_graph.adaptive_rag_graph:structured_llm created\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m adaptive_rag_graph.route_question({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m}, config=config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/site-packages/retrieval_graph/adaptive_rag_graph.py:282\u001b[39m, in \u001b[36mroute_question\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    280\u001b[39m question_router = route_prompt | structured_llm_router\n\u001b[32m    281\u001b[39m question = state.question\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m    283\u001b[39m messages = [HumanMessage(content=state.question)]\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m#source = await question_router.ainvoke({\"question\": question})\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'question'"
     ]
    }
   ],
   "source": [
    "result = await adaptive_rag_graph.route_question({\"question\": \"test\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Router\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "# print(\n",
    "#    question_router.invoke(\n",
    "#        {\"question\": \"Who will the Bears draft first in the NFL draft?\"}\n",
    "#    )\n",
    "# )\n",
    "# print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))\n",
    "\n",
    "r = await question_router.ainvoke({\"question\": \"What are the types of agent memory?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
