"""Define the configurable parameters for the agent."""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Annotated

from retrieval_agents.agents import prompts
from retrieval_agents.indexers.configurations import IndexConfiguration


@dataclass(kw_only=True)
class RagConfiguration(IndexConfiguration):
    """The configuration for the agent."""

    response_system_prompt: str = field(
        default=prompts.RESPONSE_SYSTEM_PROMPT,
        metadata={"description": "The system prompt used for generating responses."},
    )

    response_model: Annotated[str, {"__template_metadata__": {"kind": "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={
            "description": "The language model used for generating responses. Should be in the form: provider/model-name."
        },
    )

    query_system_prompt: str = field(
        default=prompts.QUERY_SYSTEM_PROMPT,
        metadata={
            "description": "The system prompt used for processing and refining queries."
        },
    )

    query_model: Annotated[str, {"__template_metadata__": {"kind": "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={
            "description": "The language model used for processing and refining queries. Should be in the form: provider/model-name."
        },
    )


@dataclass(kw_only=True)
class ARagConfiguration(IndexConfiguration):
    """The configuration for the adaptive rag agent."""

    router_model: Annotated[str, {"__template_metadata__": {"kind": "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={
            "description": "The language model used for routing the user questions."
        },
    )

    router_system_prompt: str = field(
        default=prompts.ROUTER_SYSTEM_PROMPT,
        metadata={"description": "The system prompt used for routing questions."},
    )

    topics: str = field(
        default="agents, prompt engineering, and adversarial attacks",
        metadata={"description": "The topics to retrieve."},
    )
    rewrite_system_prompt: str = field(
        default=prompts.REWRITE_SYSTEM_PROMPT,
        metadata={"description": "The prompt used for rewrite the question."},
    )

    rewrite_human_propmt: str = field(
        default=prompts.REWRITE_HUMAN_PROMPT,
    )

    rewrite_model: Annotated[str, {"__metadata__": {"kind", "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={
            "description": "The language model used for rewriting the questions."
        },
    )

    answer_grader_model: Annotated[str, {"__metadata__": {"kind": "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={
            "description": "The language model used for grading the answer generated by the LLM whether it based on the facts"
        },
    )

    answer_grader_system_prompt: str = field(
        default=prompts.ANSWER_GRADER_SYSTEM_PROMPT,
        metadata={"description": "The system prompt for grading the generated answer."},
    )

    answer_grader_human_prompt: str = field(
        default=prompts.ANSWER_GRADER_HUMAN_PROMPT,
        metadata={"description": "The human prompt for grading the generated answer."},
    )

    generate_human_prompt: str = field(
        default=prompts.GENERATE_HUMAN_PROMPT,
        metadata={
            "description": "The prompt used for answering the question based on the retrieved context."
        },
    )

    hallucination_grader_model: Annotated[
        str, {"__template__metadata__"} : {"kind": "llm"}
    ] = field(
        default="openai/gpt-4o",
        metadata={"description": "The language model used for grading hallucination."},
    )

    hallucination_grader_system_prompt: str = field(
        default=prompts.HALLUCINATION_GRADER_SYSTEM_PROMPT,
        metadata={
            "description": "The prompt used for grading the answer generated by the LLM whether it based on the facts."
        },
    )

    hallucination_grader_human_prompt: str = field(
        default=prompts.HALLUCINATION_GRADER_HUMAN_PROMPT,
        metadata={
            "description": "The human prompt used for grading the answer gerated by the LLM whether it based on the facts"
        },
    )

    grade_documents_model: Annotated[
        str, {"__template_metadata__": {"kind": "llm"}}
    ] = field(
        default="openai/gpt-4o",
        metadata={"description": "The language model used for grading the documents."},
    )

    grade_documents_system_prompt: str = field(
        default=prompts.GRADE_DOCUMENTS_SYSTEM_PROMPT,
        metadata={"description": "The system prompt used for grading the documents."},
    )

    grade_documents_human_prompt: str = field(
        default=prompts.GRADE_DOCUMENTS_HUMAN_PROMPT,
        metadata={"description": "The human prompt used for grading the documents."},
    )

    generate_model: Annotated[str, {"__template_metadata__": {"kind": "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={"description": "The language model used for generating."},
    )

    max_generation: int = field(
        default=3, metadata={"description": "The maximum number of generation."}
    )
